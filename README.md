# Commands 
docker-compose up -d
docker-compose down
docker-compose up --scale <svc_name> = 3

# Deploy to gcr.io
docker build -t fastapi-docker --platform linux/amd64 .

docker tag fastapi-docker gcr.io/<project_name>/fastapi-docker:latest

docker push gcr.io/<project_name>/fastapi-docker:latest

# Docker viz
docker run --rm -it --name dcv -v $(pwd):/input pmsipilot/docker-compose-viz render -m image docker-compose.yml

# Docker Compose
Docker Compose is a tool provided by Docker that allows you to define and run multi-container Docker applications. It uses YAML configuration files to define the services, networks, and volumes required for your application, making it easy to manage complex containerized applications with multiple interconnected components.
Docker Compose allows you to define your application's services, dependencies, and configurations in a single YAML file called `docker-compose.yml`. Each service in the file represents a containerized component of your application, such as a web server, database, or caching layer.

With Docker Compose, you can start, stop, and manage multiple containers as a single application stack using simple commands like `docker-compose up`, `docker-compose down`, `docker-compose start`, and `docker-compose stop`. This simplifies the process of managing complex containerized applications with multiple interconnected
Docker Compose automatically manages dependencies between services and ensures that they are started and stopped in the correct order. For example, if your application depends on a database service, Docker Compose will start the database service first before starting the application service.
Docker Compose automatically creates a default network for your application, allowing containers to communicate with each other using service names as hostnames. You can also define custom networks to isolate and control the communication between services.

We can also have multiple docker-compose files 
docker-compose -f docker-compose.yml -f docker-compose.override.yml up

# Volumes
Volumes allow you to persist data generated by containers even after the containers are stopped or removed. This is useful for storing application data, logs, configuration files, and other persistent data.

# Scaling 
Docker Compose makes it easy to horizontally scale your services by simply specifying the desired number of replicas in your Compose file. This allows you to quickly scale your application up or down based on changing
demand without needing to manually manage individual containers.

# Container Communication 
By default, Docker Compose creates a virtual network for your application's containers to communicate with each other. This network allows containers to discover and interact using service names or hostnames defined in your `docker-compose.yml` file. Here's how it works:

Network Creation: When you run `docker-compose up`, Docker Compose creates a new bridge network with a unique name (based on your project name). All the services defined in your `docker-compose.yml` file are automatically connected to this network.
    
Service Discovery:Docker Compose assigns a hostname to each container that matches the service name defined in your YAML file. For example, if you have a service named "database" in your `docker-compose.yml`, the corresponding container will have a hostname of "database".
    
Communication using Service Names: Containers can then communicate with each other using these service names or hostnames. This eliminates the need to manage specific IP addresses for each container, making your application configuration more portable and easier to maintain.
    
YAML

```
services:  
  app:  
    build: .  
    ports:  
      - "8000:8000"  
    environment:  
      REDIS_HOST: redis_db  
      REDIS_PORT: 6379  
      MYSQL_HOST: mysql_db  
      MYSQL_PORT: 3306  
    depends_on:  
      - redis_db  
      - mysql_db  
  redis_db:  
    image: redis:latest```


In this example, the `app` service can connect to the `redis` service using the hostname "redis_db". The container running the `redis_db` service will be reachable at `redis_db:<port>`, where `<port>` is the exposed port defined in the `redis_db` service configuration.
